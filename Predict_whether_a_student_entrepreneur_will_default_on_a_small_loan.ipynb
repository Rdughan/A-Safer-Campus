{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNw4mAuzMA1pm0PAn1Im52",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rdughan/A-Safer-Campus/blob/main/Predict_whether_a_student_entrepreneur_will_default_on_a_small_loan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcbHv-x3lE2D"
      },
      "outputs": [],
      "source": [
        "#Import the important libraries, numpy for numerical analysis, pandas for data  manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Randomly generating data with thousand entries with the numpy library and random function, optimizing for repeatability\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "\n",
        "#Creating a DataFrame with randomly generated synthetic data using numpy\n",
        "data = pd.DataFrame({\n",
        "    \"monthly_income\": np.random.uniform(300, 2500, n),\n",
        "    \"income_stability\": np.random.uniform(0.2, 0.9, n),\n",
        "    \"savings_habit\": np.random.binomial(1, 0.4, n),\n",
        "    \"business_type_risk\": np.random.choice([0,1,2], size=n, p=[0.4,0.4,0.2]),\n",
        "    \"prior_repayment_score\": np.random.uniform(0, 1, n),\n",
        "    \"loan_to_income_ratio\": np.random.uniform(0.2, 2.5, n),\n",
        "    \"peer_guarantor\": np.random.binomial(1, 0.5, n),\n",
        "    \"time_in_school_remaining\": np.random.randint(1, 49, n)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning different weights to the features to tell the model what our priority features are.\n",
        "# Positive values increase the score while negative values reduce the score.\n",
        "# The higher the score, the higher the probability of default.\n",
        "\n",
        "logit = (\n",
        "    -2.5\n",
        "    - 0.001 * data[\"monthly_income\"]\n",
        "    - 1.8 * data[\"income_stability\"]\n",
        "    - 1.2 * data[\"savings_habit\"]\n",
        "    + 0.9 * data[\"business_type_risk\"]\n",
        "    - 2.5 * data[\"prior_repayment_score\"]\n",
        "    + 1.4 * data[\"loan_to_income_ratio\"]\n",
        "    - 1.0 * data[\"peer_guarantor\"]\n",
        "    - 0.015 * data[\"time_in_school_remaining\"]\n",
        ")\n",
        "\n",
        "prob_default = 1 / (1 + np.exp(-logit)) #Sigmoid Function converts logit to probability.\n",
        "data[\"default\"] = np.random.binomial(1, prob_default) #Simulating binary default outcomes based on probabilities.\n"
      ],
      "metadata": {
        "id": "Z_Ul5iYum8kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = Prestigious University, 1 = Community/Regional University\n",
        "data[\"university_type\"] = np.random.binomial(1, 0.3, n)\n",
        "\n",
        "# We RE-CALCULATE the risk, but this time we add a \"Bias Penalty\"\n",
        "# Notice the + 2.0 * university_type. This is a HUGE penalty for Group 1.\n",
        "logit_biased = (\n",
        "    -2.5\n",
        "    - 0.001 * data[\"monthly_income\"]\n",
        "    - 1.8 * data[\"income_stability\"]\n",
        "    + 2.0 * data[\"university_type\"]  # <--- THIS IS THE INTENTIONAL BIAS\n",
        "    - 2.5 * data[\"prior_repayment_score\"]\n",
        ")\n",
        "\n",
        "# Re-generate the outcomes based on this biased logic\n",
        "prob_default_biased = 1 / (1 + np.exp(-logit_biased))\n",
        "data[\"default_biased\"] = np.random.binomial(1, prob_default_biased)"
      ],
      "metadata": {
        "id": "PzDaZUpjxDR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the sklearn librabry\n",
        "#Splitting the data into training and testing samples\n",
        "#Applying Logistic Model to accurately identify causality\n",
        "#Using classification_report funtion to give us a report on our models perfomance.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = data.drop(\"default_biased\", axis=1) # Dropping the \"default\" feature from the data\n",
        "y = data[\"default_biased\"] # Making the default the target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")# Splitting the data sample into 25% test sample and 75% train sample, random_state=42 for repeatability\n",
        "\n",
        "model_biased= LogisticRegression(max_iter=1000,class_weight='balanced')  # To account for potential imbalance in default vrs non default cases\n",
        "model_biased.fit(X_train, y_train) #Training the model\n",
        "\n",
        "y_pred = model_biased.predict(X_test) #The model predicting the test features.\n",
        "print(classification_report(y_test, y_pred)) # Output precision, recall and F1-score to evaluate performance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDIN7y4We5tl",
        "outputId": "40cbdb21-0f89-4a96-a01c-12c82e639916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.78      0.87       245\n",
            "           1       0.05      0.60      0.10         5\n",
            "\n",
            "    accuracy                           0.78       250\n",
            "   macro avg       0.52      0.69      0.49       250\n",
            "weighted avg       0.97      0.78      0.86       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the sklearn librabry\n",
        "#Splitting the data into training and testing samples\n",
        "#Applying Logistic Model to accurately identify causality\n",
        "#Using classification_report funtion to give us a report on our models perfomance.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = data.drop(\"default\", axis=1) # Dropping the \"default\" feature from the data\n",
        "y = data[\"default\"] # Making the default the target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")# Splitting the data sample into 25% test sample and 75% train sample, random_state=42 for repeatability\n",
        "\n",
        "model = LogisticRegression(max_iter=1000,class_weight='balanced')  # To account for potential imbalance in default vrs non default cases\n",
        "model.fit(X_train, y_train) #Training the model\n",
        "\n",
        "y_pred = model.predict(X_test) #The model predicting the test features.\n",
        "print(classification_report(y_test, y_pred)) # Output precision, recall and F1-score to evaluate performance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgv6AAZhpVSU",
        "outputId": "a562c859-1924-4915-8675-c4f597398cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.80      0.89       239\n",
            "           1       0.16      0.82      0.27        11\n",
            "\n",
            "    accuracy                           0.80       250\n",
            "   macro avg       0.58      0.81      0.58       250\n",
            "weighted avg       0.95      0.80      0.86       250\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oFTi_desPvyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This shows the \"importance\" the model assigned to each feature\n",
        "coef_df = pd.DataFrame({\"Feature\": X.columns, \"Coefficient\": model.coef_[0]})\n",
        "print(coef_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6yGkVN9rRwc",
        "outputId": "6159de23-86d4-46fb-ba65-18ea806082e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Feature  Coefficient\n",
            "0            monthly_income    -0.000767\n",
            "1          income_stability    -1.961049\n",
            "2             savings_habit    -2.020779\n",
            "3        business_type_risk     0.977382\n",
            "4     prior_repayment_score    -2.627633\n",
            "5      loan_to_income_ratio     0.530588\n",
            "6            peer_guarantor    -1.177729\n",
            "7  time_in_school_remaining     0.004894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Side-by-side Coefficient Comparison\n",
        "\n",
        "# Get the features and coefficients for the \"Clean Model\"\n",
        "clean_model_features = X.columns\n",
        "clean_model_coefficients = model.coef_[0]\n",
        "\n",
        "# Get the features for the \"Biased Model\" and create a Series for its coefficients\n",
        "# Note: biased_model_X_cols represents the features used to train model_biased\n",
        "biased_model_X_cols = data.drop(\"default_biased\", axis=1).columns\n",
        "biased_model_coefficients_series = pd.Series(model_biased.coef_[0], index=biased_model_X_cols)\n",
        "\n",
        "# Align the biased model coefficients with the clean model features for comparison\n",
        "# Features present in clean_model_features but not in biased_model_X_cols will get NaN (e.g., 'default_biased')\n",
        "# Features present in biased_model_X_cols but not in clean_model_features will be dropped (e.g., 'default')\n",
        "aligned_biased_model_coefficients = biased_model_coefficients_series.reindex(clean_model_features)\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"Feature\": clean_model_features,\n",
        "    \"Clean Model\": clean_model_coefficients,\n",
        "    \"Biased Model\": aligned_biased_model_coefficients.values # Convert Series to numpy array\n",
        "})\n",
        "print(comparison)"
      ],
      "metadata": {
        "id": "xzHcj02B0Mlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c17161-ed16-4002-914c-8ef0f7c36e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Feature  Clean Model  Biased Model\n",
            "0            monthly_income    -0.000792     -0.005272\n",
            "1          income_stability    -2.009511     -1.306058\n",
            "2             savings_habit    -2.119550     -0.006720\n",
            "3        business_type_risk     0.972681      0.401604\n",
            "4     prior_repayment_score    -2.741376     -0.432101\n",
            "5      loan_to_income_ratio     0.542531      0.655558\n",
            "6            peer_guarantor    -1.170389     -0.089351\n",
            "7  time_in_school_remaining     0.007203      0.034060\n",
            "8           university_type     0.472424      2.108455\n",
            "9            default_biased    -1.182459           NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are showing  the probability of default\n",
        "data[\"predicted_default_prob\"] = model.predict_proba(X)[:,1]\n"
      ],
      "metadata": {
        "id": "fLgcv6Zeu7gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A decision-making filter function based on the probability of default\n",
        "def decision(prob):\n",
        "    if prob <= 0.15:\n",
        "        return \"approve\"\n",
        "    elif prob <= 0.35:\n",
        "        return \"review\"\n",
        "    else:\n",
        "        return \"reject\"\n",
        "\n",
        "data[\"decision\"] = data[\"predicted_default_prob\"].apply(decision)\n"
      ],
      "metadata": {
        "id": "8f9Oc-R7xunV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A decision-making filter function based on the probability of default\n",
        "def decision(prob):\n",
        "    if prob <= 0.10:\n",
        "        return \"approve\"\n",
        "    elif prob <= 0.30:\n",
        "        return \"review\"\n",
        "    else:\n",
        "        return \"reject\"\n",
        "\n",
        "data[\"decision\"] = data[\"predicted_default_prob\"].apply(decision)\n"
      ],
      "metadata": {
        "id": "1GRf66wucpXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Policy Optimization Via Expected Value\n"
      ],
      "metadata": {
        "id": "002hxnkuPzUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "approve_thresholds = np.arange(0.05, 0.21, 0.02)   # 5% → 20%\n",
        "review_thresholds  = np.arange(0.20, 0.51, 0.05)   # 20% → 50%\n"
      ],
      "metadata": {
        "id": "Cia6ugF6e1DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "-3D4S1UKQIDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "approve < review\n"
      ],
      "metadata": {
        "id": "UKJufrLyQQb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for a in approve_thresholds:\n",
        "    for r in review_thresholds:\n",
        "        if a >= r:\n",
        "            continue\n",
        "\n",
        "        def policy(prob):\n",
        "            if prob <= a:\n",
        "                return \"approve\"\n",
        "            elif prob <= r:\n",
        "                return \"review\"\n",
        "            else:\n",
        "                return \"reject\"\n",
        "\n",
        "        temp = data.copy()\n",
        "        temp[\"decision\"] = temp[\"predicted_default_prob\"].apply(policy)\n",
        "\n",
        "        portfolio = temp[temp[\"decision\"] != \"reject\"]\n",
        "\n",
        "        total_ev = portfolio[\"expected_value\"].sum()\n",
        "        avg_ev   = portfolio[\"expected_value\"].mean()\n",
        "        loans    = len(portfolio)\n",
        "\n",
        "        results.append({\n",
        "            \"approve_th\": round(a, 2),\n",
        "            \"review_th\": round(r, 2),\n",
        "            \"total_ev\": total_ev,\n",
        "            \"avg_ev\": avg_ev,\n",
        "            \"loans\": loans\n",
        "        })\n"
      ],
      "metadata": {
        "id": "BzccRnDMQWT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "results_df = results_df.sort_values(\n",
        "    by=[\"total_ev\", \"loans\"],\n",
        "    ascending=[False, False]\n",
        ")\n",
        "\n",
        "results_df.head(10)\n"
      ],
      "metadata": {
        "id": "GfbclpzEQr5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the expected value of the loan\n",
        "\n",
        "LOSS = -700     # default loss\n",
        "GAIN = 200      # successful repayment gain\n",
        "\n",
        "def expected_value(prob):\n",
        "    return (1 - prob) * GAIN + prob * LOSS\n",
        "\n",
        "data[\"expected_value\"] = data[\"predicted_default_prob\"].apply(expected_value)\n"
      ],
      "metadata": {
        "id": "6D1ZNjsNxw_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the expected value of all loans that were not rejected, their average and the total number of them\n",
        "\n",
        "portfolio = data[data[\"decision\"] != \"reject\"]\n",
        "\n",
        "total_ev = portfolio[\"expected_value\"].sum()\n",
        "avg_ev = portfolio[\"expected_value\"].mean()\n",
        "\n",
        "total_loans = len(portfolio)\n",
        "\n",
        "total_ev, avg_ev, total_loans\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymqKLh-RzNA0",
        "outputId": "70f723c2-ff87-4e84-b308-6f8ed7fe16b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(60755.09449302764), np.float64(91.08709819044624), 667)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy of the data to stress test it under an economic recession where monthly income were averagely down by 20%.\n",
        "\n",
        "shock_data = data.copy()\n",
        "shock_data[\"monthly_income\"] *= 0.8\n",
        "\n",
        "shock_probs = model.predict_proba(shock_data[X.columns])[:,1]\n",
        "shock_data[\"shock_prob\"] = shock_probs\n",
        "shock_data[\"shock_ev\"] = shock_data[\"shock_prob\"].apply(expected_value)\n",
        "\n",
        "shock_data[shock_data[\"decision\"] != \"reject\"][\"shock_ev\"].sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk7t8vxa0iKr",
        "outputId": "c2cf96c7-ee48-437d-c530-5d4f4a2a695a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(46726.3248189415)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbDYyS001xWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f37f9488",
        "outputId": "35df9388-2231-4f61-f601-a18e48f0ce61"
      },
      "source": [
        "# Finding out the difference in expected value in normal times against recession times.\n",
        "\n",
        "difference_ev = total_ev - shock_data[shock_data[\"decision\"] != \"reject\"][\"shock_ev\"].sum()\n",
        "print(f\"Difference in total expected value: {difference_ev}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in total expected value: 14028.769674086136\n"
          ]
        }
      ]
    }
  ]
}